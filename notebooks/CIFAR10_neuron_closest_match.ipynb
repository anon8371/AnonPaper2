{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pandas as pd \n",
    "import json \n",
    "import copy \n",
    "import pickle \n",
    "import os \n",
    "import sys\n",
    "import copy\n",
    "import umap\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path.append('../py_scripts')\n",
    "from py_scripts import LightningDataModule, get_params_net_dataloader\n",
    "from py_scripts import Vanilla_Dataset, calculate_fid_given_torch_datasets, calculate_means_and_covs_given_torch_datasets, calculate_frechet_distance, calculate_single_mean_and_cov_given_torch_dataset\n",
    "import glob\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from diffusion_utils import *\n",
    "\n",
    "# DONT NEED TO USE GPU HERE\n",
    "\n",
    "use_gpu = True \n",
    "\n",
    "if use_gpu: \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else: \n",
    "    device=\"cpu\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/196 [00:00<?, ?it/s]/home/tbricken/scratch_link/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 196/196 [00:54<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acts shape (50000, 2048)\n",
      "Noise amount: 0.0\n",
      "Checkpoints found ['../../scratch_link/Foundational-SDM/wandb_Logger/0.0Interpretable_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1/version_None/checkpoints/epoch=999-step=49000.ckpt']\n",
      "Load from checkpoint ../../scratch_link/Foundational-SDM/wandb_Logger/0.0Interpretable_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1/version_None/checkpoints/epoch=999-step=49000.ckpt /home/tbricken/SDM-Diffusion/notebooks\n",
      "activity threshold is: 0.0\n",
      "SDM_DIFFUSION(\n",
      "  (sdm_module): SDMBase(\n",
      "    (net): Sequential(\n",
      "      (0): TrackedMLPLayer(\n",
      "        (act_func): ReLU()\n",
      "        (layer): Linear(in_features=3072, out_features=10000, bias=False)\n",
      "      )\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=10000, out_features=3072, bias=False)\n",
      "    )\n",
      "    (X_a): Linear(in_features=3072, out_features=10000, bias=False)\n",
      "    (top_k): ReLU()\n",
      "    (X_vT): Linear(in_features=10000, out_features=3072, bias=False)\n",
      "  )\n",
      "  (net): Sequential(\n",
      "    (0): NoiseLayer()\n",
      "    (1): Sequential(\n",
      "      (0): TrackedMLPLayer(\n",
      "        (act_func): ReLU()\n",
      "        (layer): Linear(in_features=3072, out_features=10000, bias=False)\n",
      "      )\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=10000, out_features=3072, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (X_a): Linear(in_features=3072, out_features=10000, bias=False)\n",
      "  (X_vT): Linear(in_features=10000, out_features=3072, bias=False)\n",
      ")\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'active_inds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/tbricken/SDM-Diffusion/notebooks/CIFAR10_neuron_closest_match.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bchaitanya1.ailab.res.ibm.com/home/tbricken/SDM-Diffusion/notebooks/CIFAR10_neuron_closest_match.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bchaitanya1.ailab.res.ibm.com/home/tbricken/SDM-Diffusion/notebooks/CIFAR10_neuron_closest_match.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m#######\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bchaitanya1.ailab.res.ibm.com/home/tbricken/SDM-Diffusion/notebooks/CIFAR10_neuron_closest_match.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m rand_inds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(active_inds, \u001b[39m50\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bchaitanya1.ailab.res.ibm.com/home/tbricken/SDM-Diffusion/notebooks/CIFAR10_neuron_closest_match.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m ws \u001b[39m=\u001b[39m min_max_scale( model\u001b[39m.\u001b[39mX_a\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdetach()[rand_inds] )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bchaitanya1.ailab.res.ibm.com/home/tbricken/SDM-Diffusion/notebooks/CIFAR10_neuron_closest_match.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m gridshow( ws\u001b[39m.\u001b[39mview(\u001b[39m50\u001b[39m, \u001b[39m3\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m32\u001b[39m), title\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKeys | Random Neurons | Noise amount=\u001b[39m\u001b[39m{\u001b[39;00mrun\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, nimages\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'active_inds' is not defined"
     ]
    }
   ],
   "source": [
    "#LowerLR\n",
    "model_template = \"Interpretable_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "#\"_ffnCIFAR10_w_Projections_Adam_lr0.0001_datas=None_10000Neurons_projM=True_nlayers1\"\n",
    "#\"_ffnRaw_CIFAR10_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\" #\"_ffnRaw_CIFAR10_Adam_lr1e-05_datas=None_10000Neurons_projM=False_nlayers1\"#\"_ffnBaseline_Adam_lr0.0001_datas=None_1steps_10000Neurons_projM=False_nlayers1\"\n",
    "\n",
    "use_CIFAR10 = True \n",
    "\n",
    "compute_fid = True\n",
    "\n",
    "bs=10\n",
    "\n",
    "model_prefixes = [0.0,0.05,0.1,0.3,0.8,1.5, 3.0, 10.0]\n",
    "#[\"100N\",\"1_000N\",\"10_000N\",\"100_000N\"]\n",
    "\n",
    "dataset_path=\"../data/\"\n",
    "save_dir = \"../../scratch_link/Foundational-SDM/data/CachedLatents/\"\n",
    "extra = {\"use_wandb\":False}\n",
    "\n",
    "if \"CIFAR10\" in model_template or use_CIFAR10: \n",
    "    latent, labels = torch.load('../data/CIFAR10/all_data_train.pt')\n",
    "    latent = latent.flatten(start_dim=1 )\n",
    "    if latent.dtype is torch.uint8:#\"/ImageNet32/\" in self.dataset_path or \"/CIFAR10/\" in self.dataset_path:\n",
    "            latent = latent.type(torch.float)/255\n",
    "else: \n",
    "\n",
    "    latent, labels = torch.load('../data/CachedOutputs/ConvMixerWTransforms_ImgNet32_CIFAR10/all_data_train.pt')\n",
    "\n",
    "latent = latent.to(device )\n",
    "\n",
    "\n",
    "if compute_fid: \n",
    "    dims = 2048\n",
    "    batch_size = 256\n",
    "    num_workers = 0\n",
    "    m1,s1 = calculate_single_mean_and_cov_given_torch_dataset( Vanilla_Dataset(latent.view(len(latent), 3, 32, 32)), batch_size , device, dims, num_workers)\n",
    "\n",
    "li_mean_max_cosine_sim = []\n",
    "li_weighted_mean_max_cosine_sim = []\n",
    "li_fid = []\n",
    "for run_ind, run in enumerate(model_prefixes): \n",
    "    print(\"Noise amount:\", run)\n",
    "\n",
    "    model, params = load_model(f\"{run}{model_template}\", dataset_path, save_dir, device, extra_extras=extra)\n",
    "\n",
    "    if run_ind ==0:\n",
    "        print(model)\n",
    "\n",
    "    #######\n",
    "\n",
    "    rand_inds = np.random.choice(active_inds, 50)\n",
    "    ws = min_max_scale( model.X_a.weight.detach()[rand_inds] )\n",
    "    gridshow( ws.view(50, 3,32,32), title=f\"Keys | Random Neurons | Noise amount={run}\", nimages=50 )\n",
    "\n",
    "\n",
    "    # rows are neurons. \n",
    "    dists = cosine_sim_matrices(model.X_a.weight.detach(), latent)  \n",
    "    #dists = torch.cdist(model.X_a.weight.detach(), latent/torch.norm(latent,dim=1, keepdim=True), p=2.0)\n",
    "\n",
    "    dist_vals, dist_inds = dists.max(dim=1) #dists.min(dim=1) #dists.max(dim=1)\n",
    "    neuron_active_summer = get_active_neurons(model, latent, device, params.nneurons[0])\n",
    "    active_mask = neuron_active_summer>0.0001\n",
    "\n",
    "    mean_max_cosine_sim = dist_vals.mean()\n",
    "    weighted_mean_max_cosine_sim = (dist_vals* (neuron_active_summer/neuron_active_summer.sum())).sum()\n",
    "\n",
    "    plt.scatter(neuron_active_summer.cpu(), dist_vals.cpu())\n",
    "    plt.xlabel(\"Neuron activity\")\n",
    "    plt.ylabel(\"Max cosine similarity\")\n",
    "\n",
    "    plt.title(\"Max cosine sim as a function of neuron activity\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"weighted mean max cosine sim\", weighted_mean_max_cosine_sim,\"| mean max cosine sim\", mean_max_cosine_sim)\n",
    "\n",
    "    li_mean_max_cosine_sim.append(mean_max_cosine_sim.cpu())\n",
    "    li_weighted_mean_max_cosine_sim.append(weighted_mean_max_cosine_sim.cpu())\n",
    "\n",
    "    print(\"Fraction of alive neurons\", active_mask.type(torch.float).mean())\n",
    "\n",
    "    kvals, kinds = torch.topk(dist_vals, bs)\n",
    "    print(f\"Top {bs} cosine sims\", kvals)\n",
    "    print(\"Most active neuron is\", neuron_active_summer.max())\n",
    "    print(f\"How active each of these neurons is:\", neuron_active_summer[kinds])\n",
    "    print(f\"Activity as a percentage:\", neuron_active_summer[kinds]/neuron_active_summer.sum())\n",
    "    ws = min_max_scale( model.X_a.weight.detach()[kinds] )\n",
    "    gridshow( ws.view(bs, 3,32,32), title=f\"Keys | Highest Cosine Similarity Neuron | Noise amount={run}\" )\n",
    "    gridshow( latent[dist_inds[kinds]].view(bs, 3,32,32), title=f\"Closest Images | Noise amount={run}\" )\n",
    "\n",
    "    ws = min_max_scale( model.X_v().detach()[kinds] )\n",
    "    gridshow( ws.view(bs, 3,32,32), title=f\"Values | Highest Cosine Similarity Neuron | Noise amount={run}\" )\n",
    "\n",
    "    print(\"----------\")\n",
    "\n",
    "    active_inds = torch.arange(params.nneurons[0])[active_mask]\n",
    "    rand_inds = np.random.choice(active_inds, bs)\n",
    "    ws = min_max_scale( model.X_a.weight.detach()[rand_inds] )\n",
    "    gridshow( ws.view(bs, 3,32,32), title=f\"Random Active Neurons Keys | Noise amount={run}\" )\n",
    "\n",
    "    gridshow( latent[dist_inds[rand_inds]].view(bs, 3,32,32), title=f\"Closest Images | Noise amount={run}\" )\n",
    "\n",
    "    print(\"----------\")\n",
    "\n",
    "    _, act_inds = torch.topk(neuron_active_summer, bs)\n",
    "    ws = min_max_scale( model.X_a.weight.detach()[act_inds] )\n",
    "    gridshow( ws.view(bs, 3,32,32), title=f\"Most Active Neurons Keys | Noise amount={run}\" )\n",
    "\n",
    "    gridshow( latent[dist_inds[act_inds]].view(bs, 3,32,32), title=f\"Closest Images | Noise amount={run}\" )\n",
    "\n",
    "    ws = min_max_scale( model.X_v().detach()[act_inds] )\n",
    "    gridshow( ws.view(bs, 3,32,32), title=f\"Values | Most Active Neurons | Noise amount={run}\" )\n",
    "\n",
    "    print(\"----------\")\n",
    "\n",
    "    _, top_most_act_inds = torch.topk(dists[act_inds[0]], bs)\n",
    "    gridshow( latent[top_most_act_inds].view(bs, 3,32,32), title=f\"Closest Images for most active neuron | Noise amount={run}\" )\n",
    "\n",
    "    if compute_fid:\n",
    "        print(\"Computing FID\")\n",
    "        m2,s2 = calculate_single_mean_and_cov_given_torch_dataset( Vanilla_Dataset(model.X_a.weight.detach().view(params.nneurons[0],3,32,32)), batch_size , device, dims, num_workers)\n",
    "\n",
    "        fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n",
    "        li_fid.append(fid_value)\n",
    "        print(\"FID is:\", fid_value)\n",
    "\n",
    "plt.scatter(model_prefixes, li_mean_max_cosine_sim, label=\"uniform\")\n",
    "plt.scatter(model_prefixes, li_weighted_mean_max_cosine_sim, label=\"weighted\")\n",
    "plt.xlabel(\"Diff Noise\")\n",
    "plt.ylabel(\"Cosine similarity\")\n",
    "plt.legend()\n",
    "plt.title(\"Average Max Cosine similarity for each neuron as a function of diffusion noise\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(model_prefixes, li_fid, label=\"FID Scores\")\n",
    "plt.xlabel(\"Diff Noise\")\n",
    "plt.ylabel(\"FID Score\")\n",
    "plt.legend()\n",
    "plt.title(\"FID of Neurons Receptive fields as a function of diffusion noise (lower is better)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ab95d2732a92093d9ea778b6aa24b3919e4e23eea354fb78837ca91d80ad5a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
